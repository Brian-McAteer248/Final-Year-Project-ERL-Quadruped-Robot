# python

def sysCall_init():
    sim = require('sim')
    self.sim = sim

    # If torso is more than 0.1 units lower than its original z position,
    # we determine that robot has fallen over (episode will terminate early)
    self.max_torso_z_deviation = 0.1


def sysCall_actuation():
    # put your actuation code here
    pass


def sysCall_sensing():
    # put your sensing code here
    pass


def sysCall_cleanup():
    # do some clean-up here
    pass


def reset(random_action_sample):
    print('\nReset')

    self.torso = self.sim.getObject('/quadruped_robot')

    self.joints = {
        'back_left_leg_hip_pitch_rev_joint': self.sim.getObject('/back_left_leg_hip_pitch_rev_joint'),
        'front_left_leg_hip_pitch_rev_joint': self.sim.getObject('/front_left_leg_hip_pitch_rev_joint'),
        'back_right_leg_hip_pitch_rev_joint': self.sim.getObject('/back_right_leg_hip_pitch_rev_joint'),
        'front_right_leg_hip_pitch_rev_joint': self.sim.getObject('/front_right_leg_hip_pitch_rev_joint'),
        'back_left_leg_knee_pitch_rev_joint': self.sim.getObject('/back_left_leg_knee_pitch_rev_joint'),
        'front_left_leg_knee_pitch_rev_joint': self.sim.getObject('/front_left_leg_knee_pitch_rev_joint'),
        'back_right_leg_knee_pitch_rev_joint': self.sim.getObject('/back_right_leg_knee_pitch_rev_joint'),
        'front_right_leg_knee_pitch_rev_joint': self.sim.getObject('/front_right_leg_knee_pitch_rev_joint')
    }

    self.joint_positions_prev_time_step = [0 for joint in self.joints]

    self.leg_bottoms = {
        'back_left_leg_bottom': self.sim.getObject('/back_left_leg_bottom'),
        'front_left_leg_bottom': self.sim.getObject('/front_left_leg_bottom'),
        'back_right_leg_bottom': self.sim.getObject('/back_right_leg_bottom'),
        'front_right_leg_bottom': self.sim.getObject('/front_right_leg_bottom')
    }

    torso_position = self.sim.getObjectPosition(self.torso)
    self.initial_y_pos = torso_position[1]
    self.initial_z_pos = torso_position[2]

    # Ensure that all joints are in position control mode
    # Vary the initial contains (initial joint positions) to allow the agent to better explore
    for index, joint in enumerate(self.joints.values()):
        self.sim.setObjectInt32Param(joint, self.sim.jointintparam_dynctrlmode, self.sim.jointdynctrl_position)
        self.sim.setJointTargetPosition(joint, random_action_sample[index])
        self.joint_positions_prev_time_step[index] = random_action_sample[index]
        # This sets the maximum torque that can be exerted on a joint when it is in position control mode
        self.sim.setJointTargetForce(joint, 5)


def get_observations():
    torso_position = self.sim.getObjectPosition(self.torso)
    torso_orientation = self.sim.getObjectOrientation(self.torso)
    torso_linear_velocity, torso_angular_velocity = self.sim.getObjectVelocity(self.torso)

    joint_positions = [self.sim.getJointPosition(joint) for joint in self.joints.values()]
    joint_velocities = [self.sim.getJointVelocity(joint) for joint in self.joints.values()]

    # sim.getContactInfo():
    # 0 for dynamic pass arg to retrieve contacts from the first dynamics engine sub-step per time step
    # 0 for index arg to retrieve first returned contact (there will only be one anyway in this case as
    # dynamicPass is set to 0)

    # Third value in the tuple returned from self.sim.getContactInfo() is a
    # vector that represents the force generated by the contact

    feet_contact_forces = [self.sim.getContactInfo(0, foot, 0)[2] for foot in self.leg_bottoms.values()]
    # Place [0,0,0] in place of empty list returned when lower leg is
    # not in contact with the ground (or any other object).
    # This is to ensure that the observations array being passed
    # to the actor neural network is always the same length.
    feet_contact_forces_std_length = [foot_contact_force if len(foot_contact_force) > 0 else [0, 0, 0]
                                      for foot_contact_force in feet_contact_forces]

    observations = []
    observations.extend(torso_position)
    observations.extend(torso_orientation)
    observations.extend(torso_linear_velocity)
    observations.extend(torso_angular_velocity)

    # Joint position values will be radian values
    observations.extend(joint_positions)

    # Joint velocities are angular velocities - radians per second
    observations.extend(joint_velocities)

    for foot_contact_force in feet_contact_forces_std_length:
        observations.extend(foot_contact_force)

    # Previous step joint positions are recorded in the step() method
    observations.extend(self.joint_positions_prev_time_step)

    return observations


def apply_positions(positions_list):
    for index, joint in enumerate(self.joints.values()):
        self.sim.setJointTargetPosition(joint, positions_list[index])

    self.joint_positions_prev_time_step = positions_list


def get_reward_and_if_robot_fallen(max_steps, steps_left, positions_list):
    torso_linear_velocity, torso_angular_velocity = self.sim.getObjectVelocity(self.torso)
    forward_velocity_x = torso_linear_velocity[0]

    # Duration reward increases as an episode progresses (this rewards
    # the robot policy for staying standing for longer)
    duration_reward = 25 * ((max_steps - steps_left) / max_steps)

    torso_position = self.sim.getObjectPosition(self.torso)
    torso_position_y = torso_position[1]
    torso_position_z = torso_position[2]

    torso_y_deviation = self.initial_y_pos - torso_position_y
    torso_height_error = self.initial_z_pos - torso_position_z

    torso_orientation = self.sim.getObjectOrientation(self.torso, self.sim.handle_world)
    torso_roll_x = torso_orientation[0]
    torso_pitch_y = torso_orientation[1]

    # Reward function:
    # - Maximise forward velocity
    # - Reward for every time step the robot does not fall over (duration/survival reward)
    # - Penalty for torso deviating from desired height
    # - Penalty for torso deviating from initial y-axis line (we want the robot to move in a straight line)
    # - Penalty for torso roll
    # - Penalty for torso pitch (^ want to keep torso roll and pitch close to 0 to keep torso
    #   parallel to the ground)
    # - Penalty for large changes in joint angles immediately after the previous timestep (prevent the
    #   robot from using aggressive motions that don't yield very realistic physical results)

    reward = ((75 * forward_velocity_x) + duration_reward - (10 * abs(torso_height_error))
              - (5 * abs(torso_y_deviation))
              - (5 * abs(torso_roll_x)) - (5 * abs(torso_pitch_y))
              - 0.05 * (
                  sum([abs(abs(positions_list[index]) - abs(self.joint_positions_prev_time_step[index])) for index in
                       range(len(self.joints))])))

    print(f'Step reward: {reward:15.15f}')

    robot_fallen = self.initial_z_pos - torso_position_z > self.max_torso_z_deviation

    return reward, robot_fallen
